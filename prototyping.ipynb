{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0617, 0.6301, 0.1402, 0.2946, 0.2888, 0.1461],\n",
      "          [0.0952, 0.3256, 0.5204, 0.4625, 0.8959, 0.8129],\n",
      "          [0.9650, 0.2442, 0.9210, 0.2398, 0.9317, 0.0939],\n",
      "          [0.6034, 0.9018, 0.0202, 0.9215, 0.3780, 0.5504],\n",
      "          [0.1710, 0.4506, 0.9833, 0.1394, 0.0281, 0.3948],\n",
      "          [0.7193, 0.6816, 0.3467, 0.9278, 0.3472, 0.8764]]]])\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "torch.Size([15, 9])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn, Tensor, tensor, arange, zeros, cat, gather, matmul, device\n",
    "from torch.nn.functional import pad\n",
    "from torch_geometric.data import Data\n",
    "from math import log2, ceil\n",
    "\n",
    "\n",
    "class SOTLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, number_of_leaves: int, kernel_size: int, stride: int = 2, padding: int = 0, lr: float = 0.3, device = device(\"cpu\")):\n",
    "        super(SOTLayer, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.leaf_num = 2**ceil(log2(number_of_leaves))\n",
    "        self.depth = log2(self.leaf_num)\n",
    "        self.learning_rates = self.learning_rates_per_branch(lr)\n",
    "        self.nodes = nn.Parameter(data= Tensor((self.leaf_num*2)-1, self.kernel_size**2), requires_grad=False).to(device)\n",
    "        self.nodes.data.uniform_(0, 1)\n",
    "        self.node_indices = arange(self.nodes.shape[0])\n",
    "        self.device = device\n",
    "\n",
    "        #self.tree_graph = Data(x= self.nodes, edge_index = self.get_tree_edges())\n",
    "    \n",
    "    def get_tree_edges(self):\n",
    "        start, num = 0, 2\n",
    "        layers, prev_layer = [], [0]\n",
    "        for n in range(int(log2(self.leaf_num)+1)):\n",
    "            nodes_per_layer = num ** n\n",
    "            layer = list(range(start, + start + nodes_per_layer))\n",
    "            dupl_l = [val for val in prev_layer for _ in (0, 1)]\n",
    "            layers += (list(zip(dupl_l, layer)))\n",
    "            start += nodes_per_layer \n",
    "            prev_layer = layer\n",
    "        return tensor(layers[1:]).T\n",
    "    \n",
    "    def img2patches(self, x):\n",
    "        padded = pad(x, [self.padding] * 4, \"constant\", 0)\n",
    "        p = padded.unfold(2, self.kernel_size, self.stride).unfold(3, self.kernel_size, self.stride)\n",
    "        out = p.reshape(p.shape[0],p.shape[1], p.shape[2] * p.shape[3], p.shape[4] * p.shape[5])\n",
    "        output_dim_x, output_dim_y = p.shape[2], p.shape[3]\n",
    "        return out, output_dim_x, output_dim_y\n",
    "    \n",
    "    def pnorm(self, x1, x2, p=2):\n",
    "        return torch.pow(torch.pow(x1 - x2.unsqueeze(dim=3), p).sum(dim=4), p)\n",
    "    \n",
    "    def learning_rates_per_branch(self, lr: float):\n",
    "        return (lr * 2 ** arange(1,self.depth+2, dtype=torch.float)) / (2**(self.depth+1))\n",
    "    \n",
    "    def _propagate_through_tree(self, X):\n",
    "        patch_num = X.shape[2]\n",
    "        start, num = 1, 2\n",
    "        layers = []\n",
    "        layer_state = torch.zeros(patch_num, 1, dtype=int)\n",
    "        update_amount_indices = torch.zeros(2, dtype=int)\n",
    "        for n in range(1, int(log2(self.leaf_num)+1)):\n",
    "            nodes_per_layer = num ** n\n",
    "            layer = arange(start, + start + nodes_per_layer)\n",
    "            layer_state = layer_state.repeat_interleave(2).reshape(patch_num,nodes_per_layer)\n",
    "            max_val = layer_state.max(dim=1).values.unsqueeze(dim=1)\n",
    "            competing_indices = layer.repeat(patch_num,1)[layer_state == max_val].reshape(patch_num, num)\n",
    "            competing_nodes = self.nodes[competing_indices].clone().to('cpu')\n",
    "            dist = self.pnorm(competing_nodes, X)\n",
    "            bmu_dists, bmu = torch.min(dist, 3)\n",
    "            bmu_index = gather(input = competing_indices, dim = 1, index = bmu.squeeze().unsqueeze(dim=1))\n",
    "            layer_state = layer_state.add((layer == bmu_index).to(torch.int64))\n",
    "            layers.append(layer_state)\n",
    "            start += nodes_per_layer \n",
    "        return cat(layers, dim=1), bmu_index, bmu_dists\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X, output_dim_x, output_dim_y = self.img2patches(X)\n",
    "        indices, bmu_indices, bmu_dists = self._propagate_through_tree(X)\n",
    "        neighborhood_lrs = gather(input=self.learning_rates, index= indices.flatten(), dim=0).reshape(indices.shape)\n",
    "        neighborhood_updates = (neighborhood_lrs.unsqueeze(2).to(self.device) * (X.unsqueeze(3).squeeze(0).squeeze(0).to(self.device) - self.nodes[1:,:].unsqueeze(0).to(self.device))).mean(0)\n",
    "        self.nodes[1:, :] += neighborhood_updates\n",
    "        return\n",
    "    \n",
    "    \n",
    "\n",
    "from torch import rand\n",
    "import torch\n",
    "img = rand(1,1,6,6)    \n",
    "print(img)\n",
    "cuda = device('cuda') \n",
    "tree = SOTLayer(number_of_leaves = 7, \n",
    "                kernel_size = 3, \n",
    "                stride = 1, \n",
    "                padding = 0,\n",
    "                lr = 0.5,\n",
    "                device = cuda\n",
    "               )\n",
    "\n",
    "tree.forward(img)\n",
    "#a,_,_ = tree.img2patches(img)\n",
    "#s, bmu_indices, bmu_dists = tree.propagate_through_tree(img)\n",
    "#l = tree.learning_rates_per_branch(0.2)\n",
    "\n",
    "#torch.gather(input=l, index= s.flatten(), dim=0).reshape(s.shape)\n",
    "#tree.forward(img)\n",
    "print(tree.nodes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.5000, 0.2500, 0.1250])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr, depth = 0.2, 3\n",
    "#lr * \n",
    "torch.tensor(2).pow(arange(1,depth+2, dtype=torch.float)).flip(0) / (2**(depth+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.],\n",
      "        [ 0.,  1.],\n",
      "        [ 0.,  2.],\n",
      "        [ 0.,  3.],\n",
      "        [ 0.,  4.],\n",
      "        [ 0.,  5.],\n",
      "        [ 0.,  6.],\n",
      "        [ 0.,  7.],\n",
      "        [ 0.,  8.],\n",
      "        [ 0.,  9.],\n",
      "        [ 0., 10.],\n",
      "        [ 0., 11.],\n",
      "        [ 0., 12.],\n",
      "        [ 0., 13.],\n",
      "        [ 0., 14.],\n",
      "        [ 0., 15.]])\n",
      "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  2.,  2.,  0.,  0.,\n",
      "         3.,  3.,  0.,  0.,  4.,  4.,  0.,  0.,  5.,  5.,  0.,  0.,  6.,  6.,\n",
      "         0.,  0.,  7.,  7.,  0.,  0.,  8.,  8.,  0.,  0.,  9.,  9.,  0.,  0.,\n",
      "        10., 10.,  0.,  0., 11., 11.,  0.,  0., 12., 12.,  0.,  0., 13., 13.,\n",
      "         0.,  0., 14., 14.,  0.,  0., 15., 15.])\n"
     ]
    }
   ],
   "source": [
    "p = torch.zeros(1).repeat(16,1)\n",
    "l = torch.arange(16).unsqueeze(dim=1)\n",
    "a = cat((p,l),1)\n",
    "print(a)\n",
    "print(a.repeat_interleave(2))#.reshape(16,4)#.repeat(1,2)#.T#.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4812, 0.3411, 0.0650, 0.4459, 0.9007, 0.0556, 0.4408, 0.5423, 0.8323,\n",
       "        0.2666])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import rand\n",
    "import torch\n",
    "a = rand(1,1,10)    \n",
    "a.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 2, 2, 3, 3, 4, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tensor([1,2,3,4])\n",
    "b.repeat(2,1).T.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor([[1,2,3], [4,5,6], [7,8,9]])[[0,2],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Data' object has no attribute 'k_hop_subgraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cd88183f7959>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mk_hop_subgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_hop_subgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Data' object has no attribute 'k_hop_subgraph'"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "k_hop_subgraph(tree.tree_graph,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.nn.functional import pad\n",
    "from math import log2, ceil\n",
    "\n",
    "\n",
    "#torch.random.manual_seed(0)  # Set a known random seed for reproducibility\n",
    "\n",
    "\n",
    "class NewSOTT(nn.Module):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "\n",
    "    def __init__(self, kernel_size: int, leaf_num: int, \n",
    "                 niter: int, stride: int = 2, padding: int = 0, \n",
    "                 alpha: float = None, sigma: float = None, device = torch.device(\"cpu\")\n",
    "                 ):\n",
    "        super(NewSOTT, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.leaf_num = leaf_num\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.niter = niter\n",
    "        #self.locations = self._neuron_locations()\n",
    "        self.leaf_num = 2**ceil(log2(leaf_num))\n",
    "        self.nodes = torch.nn.Parameter(data=Tensor((leafNum*2)-2, kernel_size**2), requires_grad=False)\n",
    "        self.nodes.data.uniform_(0, 1)\n",
    "        if alpha is None:\n",
    "            self.alpha = 0.3\n",
    "        else:\n",
    "            self.alpha = float(alpha)\n",
    "        if sigma is None:\n",
    "            self.sigma = leaf_num / 2.0\n",
    "        else:\n",
    "            self.sigma = float(sigma)\n",
    "        #self.w = torch.randint(low=0, high=256, size = (grid_size[0] * grid_size[1], kernel_size * kernel_size), \n",
    "        #                       dtype=torch.uint8, device=device, requires_grad=False)\n",
    "        self.it = 1\n",
    "        self.device = device\n",
    "\n",
    "    def _2diImg2col(self, x):\n",
    "        padded = pad(x, [self.padding] * 4, \"constant\", 0)\n",
    "        p = padded.unfold(0, self.kernel_size, self.stride).unfold(1, self.kernel_size, self.stride)\n",
    "        out = p.reshape(p.shape[0] * p.shape[1], p.shape[2] * p.shape[3])\n",
    "        output_dim_x, output_dim_y = p.shape[0], p.shape[1]\n",
    "        return out, output_dim_x, output_dim_y\n",
    "\n",
    "    def _neuron_locations(self):\n",
    "        a, b = torch.meshgrid(torch.arange(self.grid_size[0]), torch.arange(self.grid_size[1]))\n",
    "        return torch.transpose(torch.LongTensor(torch.stack([a.flatten(), b.flatten()])), 0, 1)\n",
    "\n",
    "    def _pnorm(self, x1, x2, p=2):\n",
    "        return torch.pow(torch.pow(x1 - x2.unsqueeze(dim=1), p).sum(2), p)\n",
    "\n",
    "    def get_bmu_indices(self, x):\n",
    "        dist = self._pnorm(self.w, x)\n",
    "        _, bmu_index = torch.min(dist, 1)\n",
    "        return bmu_index\n",
    "\n",
    "    def adjust_synapses(self, x):\n",
    "        x, output_dim_x, output_dim_y = self._2diImg2col(x)\n",
    "        dist = self._pnorm(self.w, x)\n",
    "        _, bmu_index = torch.min(dist, 1)\n",
    "        bmu_loc = self.locations[bmu_index, :]\n",
    "\n",
    "        learning_rate_op = 1.0 - self.it / self.niter\n",
    "        alpha_op = self.alpha * learning_rate_op\n",
    "        sigma_op = self.sigma * learning_rate_op\n",
    "\n",
    "        bmu_distance_squares = torch.sum(torch.pow(self.locations.expand(bmu_loc.shape[0], \n",
    "                                                                         self.locations.shape[0],\n",
    "                                                                         self.locations.shape[1]) - bmu_loc.unsqueeze(dim=1), 2), 2)\n",
    "        neighbourhood_func = torch.exp(torch.neg(torch.div(bmu_distance_squares, sigma_op ** 2)))\n",
    "        learning_rate = alpha_op * neighbourhood_func\n",
    "        self.w.data += (learning_rate.unsqueeze(2) * (x.unsqueeze(dim=1) - self.w.unsqueeze(dim=0))).mean(dim=0)\n",
    "        self.it += 1\n",
    "        return bmu_loc.reshape(2, output_dim_x, output_dim_y)\n",
    "\n",
    "    def set_mode(self, m):\n",
    "        self.mode = m\n",
    "\n",
    "    def forward(self, x) -> Tensor:\n",
    "        x.to(self.device)\n",
    "        output = self.adjust_synapses(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4d6d4a6d61fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m NewSOTT(kernel_size = 3, \n\u001b[0m\u001b[1;32m      4\u001b[0m        \u001b[0mleaf_num\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0mniter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-fdded409a211>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, kernel_size, leaf_num, niter, stride, padding, alpha, sigma, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_size' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "epochs = 10\n",
    "NewSOTT(kernel_size = 3, \n",
    "       leaf_num= 100, \n",
    "       niter = epochs,\n",
    "       stride = 1,\n",
    "       device = device\n",
    "                 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
